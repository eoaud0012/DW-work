import os
import json
import time
import smtplib
from datetime import datetime as dt
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

import requests
from bs4 import BeautifulSoup  # ì¶”ê°€: BeautifulSoup ì„í¬íŠ¸
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from urllib.parse import urlparse
from newspaper import Article

# === Azure OpenAI API ë° ì´ë©”ì¼ ê´€ë ¨ ë¯¼ê° ì •ë³´ ì„¤ì • ===
azure_endpoint = "https://apim-dwdp-openai.azure-api.net/007/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-04-01-preview"
azure_subscription_key = "d932deacbffc451e84417fac864394b9"
azure_application = "nikkei_nes_scrapping_test"
azure_compCode = "industry"
azure_userID = "eoaud0012"
azure_userNM = "daemyeong_lee"
azure_serviceType = "translate"  # ë²ˆì—­ ì„œë¹„ìŠ¤

email_password = "ywad kvgh etlc nafm"  # ì•± ì „ìš© ë¹„ë°€ë²ˆí˜¸(ë˜ëŠ” SMTP ë¹„ë°€ë²ˆí˜¸)
sender_email = "eoaud0012@gmail.com"
os.environ["EMAIL_PASSWORD"] = email_password

# --------------------------------------------------------------------
# ë²ˆì—­ í•¨ìˆ˜ (Azure OpenAI API)
# --------------------------------------------------------------------
def translate_text(text):
    endpoint = azure_endpoint
    headers = {
        "Ocp-Apim-Subscription-Key": azure_subscription_key,
        "application": azure_application,
        "compCode": azure_compCode,
        "userID": azure_userID,
        "userNM": azure_userNM,
        "serviceType": azure_serviceType,
        "Content-Type": "application/json; charset=utf-8"
    }
    data = {
        "messages": [
            {"role": "system", "content": "ë„ˆëŠ” í•œêµ­ì–´ ë²ˆì—­ ë° ìš”ì•½ ë„ìš°ë¯¸ì•¼."},
            {
                "role": "user",
                "content": (
                    f"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ê³ , íšŒì‚¬ì˜ ì„ì›ì´ ë³´ì‹œëŠ” ê±°ë¼, "
                    f"ê¸°ì‚¬ì˜ í•µì‹¬ ë‚´ìš©ì„ ë¨¸ë¦¿ë§ ê¸°í˜¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ê¹”ë”í•˜ê²Œ ìš”ì•½í•´ì¤˜.:\n\n{text}"
                )
            }
        ],
        "temperature": 0.3
    }
    try:
        data_str = json.dumps(data, ensure_ascii=False).encode("utf-8")
        response = requests.post(endpoint, headers=headers, data=data_str)
        response.raise_for_status()
        response.encoding = "utf-8"
        result = response.json()
        translated_text = result["choices"][0]["message"]["content"].strip()
        return translated_text
    except Exception as e:
        print("ë²ˆì—­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)
        return text

# --------------------------------------------------------------------
# ì´ë©”ì¼ ë°œì†¡ í•¨ìˆ˜ (SMTP)
# --------------------------------------------------------------------
def send_email(subject, body, recipient):
    sender = sender_email
    email_pw = os.getenv("EMAIL_PASSWORD")
    if email_pw is None:
        print("EMAIL_PASSWORD í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return
    msg = MIMEMultipart()
    msg["From"] = sender
    msg["To"] = recipient
    msg["Subject"] = subject
    msg.attach(MIMEText(body, "plain"))
    try:
        smtp_server = "smtp.gmail.com"
        smtp_port = 587
        server = smtplib.SMTP(smtp_server, smtp_port)
        server.starttls()
        server.login(sender, email_pw)
        server.sendmail(sender, recipient, msg.as_string())
        server.quit()
        print("ì´ë©”ì¼ ë°œì†¡ ì„±ê³µ!")
    except Exception as e:
        print("ì´ë©”ì¼ ë°œì†¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)

# --------------------------------------------------------------------
# newspaper3kë¥¼ ì‚¬ìš©í•˜ì—¬ URLë¡œë¶€í„° ê¸°ì‚¬ ë³¸ë¬¸ê³¼ ì œëª© ì¶”ì¶œ
# --------------------------------------------------------------------
def get_article_text_with_newspaper(url):
    try:
        article = Article(url, language="en")
        article.download()
        article.parse()
        text = article.text if article.text.strip() else "ë³¸ë¬¸ ì—†ìŒ"
        title = article.title if article.title.strip() else "ì œëª© ì—†ìŒ"
        return title, text
    except Exception as e:
        print(f"newspaper3k ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ({url}):", e)
        return "ì œëª© ì—†ìŒ", "ë³¸ë¬¸ ì—†ìŒ"

# --------------------------------------------------------------------
# BeautifulSoupì„ ì‚¬ìš©í•˜ì—¬ í˜ì´ì§€ HTMLì—ì„œ ê¸°ì‚¬ ì»¨í…Œì´ë„ˆ(HTML êµ¬ì¡° ì°¸ê³ ) íŒŒì‹±
# --------------------------------------------------------------------
def get_articles_from_page(html):
    articles = []
    soup = BeautifulSoup(html, "html.parser")
    # ê¸°ì‚¬ ì»¨í…Œì´ë„ˆê°€ "SoaBEf" í´ë˜ìŠ¤ì¸ divë¼ê³  ê°€ì •
    containers = soup.find_all("div", class_="SoaBEf")
    for container in containers:
        # ë§í¬ ì¶”ì¶œ (í´ë˜ìŠ¤ "WlydOe"ë¥¼ ê°€ì§„ a íƒœê·¸)
        a_tag = container.find("a", class_="WlydOe")
        url = a_tag.get("href") if a_tag else None

        # ì œëª© ì¶”ì¶œ (í´ë˜ìŠ¤ "n0jPhd")
        title_tag = container.find("div", class_="n0jPhd")
        title = title_tag.get_text(strip=True) if title_tag else "ì œëª© ì—†ìŒ"

        # ìš”ì•½(ë³¸ë¬¸ ì¼ë¶€) ì¶”ì¶œ (í´ë˜ìŠ¤ "GI74Re")
        snippet_tag = container.find("div", class_="GI74Re")
        snippet = snippet_tag.get_text(strip=True) if snippet_tag else "ìš”ì•½ ì—†ìŒ"

        # ë‚ ì§œ ì •ë³´ ì¶”ì¶œ (í´ë˜ìŠ¤ "OSrXXb")
        date_tag = container.find("div", class_="OSrXXb")
        date = date_tag.get_text(strip=True) if date_tag else "ë‚ ì§œ ì—†ìŒ"

        if url:
            articles.append({
                "url": url,
                "title": title,
                "snippet": snippet,
                "date": date
            })
    return articles

# --------------------------------------------------------------------
# Seleniumìœ¼ë¡œ Google News ê²€ìƒ‰ ê²°ê³¼ í˜ì´ì§€ì—ì„œ ìŠ¤í¬ë¡¤ í›„ HTMLì„ íŒŒì‹±í•˜ì—¬ ê¸°ì‚¬ ì •ë³´ ìˆ˜ì§‘
# --------------------------------------------------------------------
def get_articles_from_google_news(driver, scrolls=3):
    # í˜ì´ì§€ë¥¼ ìŠ¤í¬ë¡¤í•˜ì—¬ ë™ì ìœ¼ë¡œ ë¡œë”©ëœ ê¸°ì‚¬ ëª¨ë‘ ë¡œë“œ
    for _ in range(scrolls):
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(2)
    html = driver.page_source
    articles = get_articles_from_page(html)
    return articles

# --------------------------------------------------------------------
# ë©”ì¸ í•¨ìˆ˜: í‚¤ì›Œë“œë³„ URL ë° ê¸°ì‚¬ ì •ë³´ ìˆ˜ì§‘, ê¸°ì‚¬ ì²˜ë¦¬, ë²ˆì—­/ìš”ì•½, ì´ë©”ì¼ ë°œì†¡
# --------------------------------------------------------------------
def main():
    keywords = [
    "Beer Market", "Soju Market"
    ]
    # ì§€ë‚œ 1ê°œì›”(30ì¼) ì´ë‚´ ê¸°ì‚¬ ê²€ìƒ‰ + ì˜ì–´/ë¯¸êµ­ ê¸°ì¤€
    GOOGLE_NEWS_URL = "https://www.google.com/search?q={query}&tbm=nws&tbs=qdr:m&hl=en&gl=us"

    chrome_options = Options()
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    # ë””ë²„ê¹… ì‹œì—ëŠ” í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ ì£¼ì„ ì²˜ë¦¬ ê°€ëŠ¥
    # chrome_options.add_argument("--headless")
    prefs = {"profile.managed_default_content_settings.images": 2}
    chrome_options.add_experimental_option("prefs", prefs)
    service = Service()
    driver = webdriver.Chrome(service=service, options=chrome_options)
    driver.set_page_load_timeout(30)

    excluded_domains = ["chosun.com", "koreatimes.co.kr", "mk.co.kr",
                        "koreaherald.com", "koreajoongangdaily.joins.com",
                        "businesskorea.co.kr"]
    collected_articles = []

    for keyword in keywords:
        print(f"ğŸ” '{keyword}' ê²€ìƒ‰ ì¤‘...")
        try:
            driver.get(GOOGLE_NEWS_URL.format(query=keyword))
        except TimeoutException:
            print(f"'{keyword}' ê²€ìƒ‰ í˜ì´ì§€ ë¡œë”© íƒ€ì„ì•„ì›ƒ ë°œìƒ. ê±´ë„ˆëœë‹ˆë‹¤.")
            continue
        time.sleep(2)
        articles = get_articles_from_google_news(driver, scrolls=5)
        print(f"'{keyword}'ì—ì„œ {len(articles)}ê°œì˜ ê¸°ì‚¬ ìˆ˜ì§‘ë¨.")
        if not articles:
            print(f"'{keyword}' ê´€ë ¨ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            continue
        # ë„ë©”ì¸ ì œì™¸ í•„í„° ì ìš©
        for article in articles:
            domain = urlparse(article["url"]).netloc.lower()
            if any(excl in domain for excl in excluded_domains):
                print(f"{domain} ê¸°ì‚¬ì´ë¯€ë¡œ ì œì™¸í•©ë‹ˆë‹¤.")
                continue
            collected_articles.append(article)
    driver.quit()

    if not collected_articles:
        print("ìˆ˜ì§‘ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"ì´ {len(collected_articles)}ê°œì˜ ê¸°ì‚¬ ì²˜ë¦¬ ì˜ˆì •.")

    email_body = ""
    for article in collected_articles:
        url = article["url"]
        title = article["title"]
        snippet = article["snippet"]
        date = article["date"]

        print(f"Processing article: {url}")
        # Newspaper3kë¡œ ë³¸ë¬¸ ì¶”ì¶œ ì‹œë„
        np_title, article_text = get_article_text_with_newspaper(url)
        # ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ê²€ìƒ‰ê²°ê³¼ì˜ ì •ë³´ë¡œ ëŒ€ì²´
        if np_title == "ì œëª© ì—†ìŒ":
            np_title = title
        if article_text == "ë³¸ë¬¸ ì—†ìŒ":
            article_text = snippet

        # ë²ˆì—­ ìš”ì²­ì—ëŠ” ë³¸ë¬¸ ë‚´ìš©ì„ ì‚¬ìš©í•˜ì§€ë§Œ,
        # ìµœì¢… ì´ë©”ì¼ê³¼ í„°ë¯¸ë„ì—ëŠ” ê¸°ì‚¬ ë³¸ë¬¸ ë‚´ìš©ì€ ë…¸ì¶œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        full_text_for_translation = f"ì œëª©: {np_title}\në§í¬: {url}\në‚ ì§œ: {date}\n\në‚´ìš©:\n{article_text}"
        translated_text = translate_text(full_text_for_translation)
        email_body += f"ì œëª©: {np_title}\në§í¬: {url}\në‚ ì§œ: {date}\n"
        email_body += f"----- ë²ˆì—­ ë° ìš”ì•½ -----\n{translated_text}\n"
        email_body += "=" * 50 + "\n\n"
        print(f"âœ… ê¸°ì‚¬ ì²˜ë¦¬ ì™„ë£Œ: {np_title}")

    subject = f"[{dt.now().strftime('%y/%m/%d')}] ì™¸êµ­ ë‰´ìŠ¤ ê¸°ì‚¬ ë²ˆì—­ ë° ìš”ì•½"
    recipient = "eoaud0012@dongwon.com"
    send_email(subject, email_body, recipient)
    # print("\nìµœì¢… ì´ë©”ì¼ ë³¸ë¬¸:\n", email_body)

if __name__ == "__main__":
    main()
